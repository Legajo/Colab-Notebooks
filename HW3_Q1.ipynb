{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0D1SZ/p/KDwOAKxSF36Ti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Legajo/Colab-Notebooks/blob/main/HW3_Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QSsYxi_zWLe",
        "outputId": "bdd8ec3f-f05d-4c7a-b921-552eff74ceb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1mb0ae2M5AouSDlqcUnIwaHq7avwGNrmB\n",
            "From (redirected): https://drive.google.com/uc?id=1mb0ae2M5AouSDlqcUnIwaHq7avwGNrmB&confirm=t&uuid=55eccb00-3677-44a6-8653-7a7c53f505c6\n",
            "To: /content/stocks_df_combined_2025_06_13.parquet.brotli\n",
            "100% 130M/130M [00:01<00:00, 75.5MB/s]\n",
            "Loading data...\n",
            "âœ“ Loaded df_full: (230262, 203)\n",
            "âœ“ Truncated to df: (191795, 203)\n",
            "\n",
            "âœ“ Features defined: 184 numerical, 4 categorical\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# HOMEWORK: Time Series Modeling with Decision Trees\n",
        "# Based on: [2025]_Module_3_Colab_Time_Series_Modeling.ipynb\n",
        "# Location: My Drive\\Colab-Notebooks\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# STAGE 0: SETUP AND DATA LOADING\n",
        "# ============================================================================\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install yfinance -q\n",
        "!pip uninstall gdown -y -q\n",
        "!pip install gdown -q\n",
        "\n",
        "# Download data file\n",
        "!gdown https://drive.google.com/file/d/1mb0ae2M5AouSDlqcUnIwaHq7avwGNrmB/view?usp=sharing --fuzzy -O /content/\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import calendar\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "# Load data\n",
        "print(\"Loading data...\")\n",
        "df_full = pd.read_parquet(\"/content/stocks_df_combined_2025_06_13.parquet.brotli\")\n",
        "print(f\"âœ“ Loaded df_full: {df_full.shape}\")\n",
        "\n",
        "# Truncate to 25 years (2000+)\n",
        "df = df_full[df_full.Date >= '2000-01-01'].copy()\n",
        "print(f\"âœ“ Truncated to df: {df.shape}\")\n",
        "\n",
        "# Define variable lists (from Module 3)\n",
        "GROWTH = [g for g in df.keys() if (g.find('growth_')==0)&(g.find('future')<0)]\n",
        "OHLCV = ['Open','High','Low','Close','Adj Close_x','Volume']\n",
        "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type']\n",
        "TO_PREDICT = [g for g in df.keys() if (g.find('future')>=0)]\n",
        "TO_DROP = ['Year','Date','index_x', 'index_y', 'index', 'Quarter','Adj Close_y'] + CATEGORICAL + OHLCV\n",
        "\n",
        "# Create custom features\n",
        "df['ln_volume'] = df.Volume.apply(lambda x: np.log(x) if x > 0 else 0)\n",
        "\n",
        "CUSTOM_NUMERICAL = ['SMA10', 'SMA20', 'growing_moving_average', 'high_minus_low_relative','volatility', 'ln_volume']\n",
        "\n",
        "TECHNICAL_INDICATORS = ['adx', 'adxr', 'apo', 'aroon_1','aroon_2', 'aroonosc',\n",
        " 'bop', 'cci', 'cmo','dx', 'macd', 'macdsignal', 'macdhist', 'macd_ext',\n",
        " 'macdsignal_ext', 'macdhist_ext', 'macd_fix', 'macdsignal_fix',\n",
        " 'macdhist_fix', 'mfi', 'minus_di', 'mom', 'plus_di', 'dm', 'ppo',\n",
        " 'roc', 'rocp', 'rocr', 'rocr100', 'rsi', 'slowk', 'slowd', 'fastk',\n",
        " 'fastd', 'fastk_rsi', 'fastd_rsi', 'trix', 'ultosc', 'willr',\n",
        " 'ad', 'adosc', 'obv', 'atr', 'natr', 'ht_dcperiod', 'ht_dcphase',\n",
        " 'ht_phasor_inphase', 'ht_phasor_quadrature', 'ht_sine_sine', 'ht_sine_leadsine',\n",
        " 'ht_trendmod', 'avgprice', 'medprice', 'typprice', 'wclprice']\n",
        "\n",
        "TECHNICAL_PATTERNS = [g for g in df.keys() if g.find('cdl')>=0]\n",
        "\n",
        "MACRO = ['gdppot_us_yoy', 'gdppot_us_qoq', 'cpi_core_yoy', 'cpi_core_mom', 'FEDFUNDS',\n",
        " 'DGS1', 'DGS5', 'DGS10']\n",
        "\n",
        "NUMERICAL = GROWTH + TECHNICAL_INDICATORS + TECHNICAL_PATTERNS + CUSTOM_NUMERICAL + MACRO\n",
        "\n",
        "print(f\"\\nâœ“ Features defined: {len(NUMERICAL)} numerical, {len(CATEGORICAL)} categorical\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STAGE 1: QUESTION 1 - DUMMIES FOR MONTH AND WEEK-OF-MONTH\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 1: QUESTION 1 - Month and Week-of-Month Dummies\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Step 1: Define week_of_month function\n",
        "def week_of_month(tgtdate):\n",
        "    \"\"\"Calculate week of month using (day - 1) // 7 + 1 formula\"\"\"\n",
        "    if isinstance(tgtdate, pd.Timestamp):\n",
        "        tgtdate = tgtdate.to_pydatetime()\n",
        "    return (tgtdate.day - 1) // 7 + 1\n",
        "\n",
        "# Step 2: Create month_wom feature\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.loc[:, 'Month'] = df['Date'].dt.strftime('%B')\n",
        "df.loc[:, 'Weekday'] = df['Date'].dt.day_name().astype(str)\n",
        "df['week_of_month'] = df['Date'].apply(week_of_month)\n",
        "df['month_wom'] = df['Month'] + '_w' + df['week_of_month'].astype(str)\n",
        "\n",
        "print(f\"\\nâœ“ Created month_wom feature\")\n",
        "print(f\"  Total unique combinations: {df['month_wom'].nunique()}\")\n",
        "print(f\"\\n  Sample values:\")\n",
        "print(df['month_wom'].value_counts().head(10))\n",
        "\n",
        "# Step 3: Update CATEGORICAL list\n",
        "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom']\n",
        "print(f\"\\nâœ“ Updated CATEGORICAL: {CATEGORICAL}\")\n",
        "\n",
        "# Step 4: Generate dummy variables\n",
        "print(\"\\nâœ“ Generating dummy variables...\")\n",
        "dummy_variables = pd.get_dummies(df[CATEGORICAL], dtype='int32')\n",
        "DUMMIES = dummy_variables.keys().to_list()\n",
        "\n",
        "print(f\"  Total dummy variables: {len(DUMMIES)}\")\n",
        "\n",
        "# Filter month_wom dummies\n",
        "month_wom_dummies = [col for col in DUMMIES if col.startswith('month_wom_')]\n",
        "print(f\"  month_wom dummies: {len(month_wom_dummies)}\")\n",
        "\n",
        "# Concatenate dummies with original dataframe\n",
        "df_with_dummies = pd.concat([df, dummy_variables], axis=1)\n",
        "\n",
        "# Step 5-8: Calculate correlations and find highest absolute correlation\n",
        "print(\"\\nâœ“ Calculating correlations...\")\n",
        "correlation_matrix = df_with_dummies[DUMMIES + ['is_positive_growth_30d_future']].corr()\n",
        "correlations = correlation_matrix['is_positive_growth_30d_future']\n",
        "\n",
        "month_wom_correlations = correlations[month_wom_dummies]\n",
        "\n",
        "# Create dataframe with abs_corr column\n",
        "month_wom_corr_df = pd.DataFrame({\n",
        "    'feature': month_wom_correlations.index,\n",
        "    'correlation': month_wom_correlations.values\n",
        "})\n",
        "month_wom_corr_df['abs_corr'] = month_wom_corr_df['correlation'].abs()\n",
        "month_wom_corr_df = month_wom_corr_df.sort_values('abs_corr', ascending=False)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Top 10 month_wom dummies by absolute correlation:\")\n",
        "print(\"=\"*70)\n",
        "print(month_wom_corr_df.head(10).to_string(index=False))\n",
        "\n",
        "max_abs_corr = month_wom_corr_df['abs_corr'].iloc[0]\n",
        "best_feature = month_wom_corr_df['feature'].iloc[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸŽ¯ ANSWER FOR QUESTION 1:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Feature: {best_feature}\")\n",
        "print(f\"Correlation: {month_wom_corr_df['correlation'].iloc[0]:.6f}\")\n",
        "print(f\"\\nâœ… ABSOLUTE CORRELATION (3 decimals): {max_abs_corr:.3f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Update new_df for next stages\n",
        "new_df = df_with_dummies.copy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncR56HNqz8JZ",
        "outputId": "bee657a2-a303-4a44-9a7d-8476e388f4ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 1: QUESTION 1 - Month and Week-of-Month Dummies\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-494447477.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['January' 'January' 'January' ... 'June' 'June' 'June']' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
            "  df.loc[:, 'Month'] = df['Date'].dt.strftime('%B')\n",
            "/tmp/ipython-input-494447477.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Monday' 'Tuesday' 'Wednesday' ... 'Wednesday' 'Thursday' 'Friday']' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[:, 'Weekday'] = df['Date'].dt.day_name().astype(str)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ“ Created month_wom feature\n",
            "  Total unique combinations: 60\n",
            "\n",
            "  Sample values:\n",
            "month_wom\n",
            "June_w1        3882\n",
            "February_w1    3878\n",
            "June_w2        3874\n",
            "May_w2         3873\n",
            "May_w3         3870\n",
            "February_w2    3842\n",
            "February_w4    3841\n",
            "January_w2     3831\n",
            "April_w4       3828\n",
            "March_w2       3812\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ“ Updated CATEGORICAL: ['Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom']\n",
            "\n",
            "âœ“ Generating dummy variables...\n",
            "  Total dummy variables: 115\n",
            "  month_wom dummies: 60\n",
            "\n",
            "âœ“ Calculating correlations...\n",
            "\n",
            "======================================================================\n",
            "Top 10 month_wom dummies by absolute correlation:\n",
            "======================================================================\n",
            "               feature  correlation  abs_corr\n",
            "  month_wom_October_w4     0.024968  0.024968\n",
            " month_wom_November_w3     0.022097  0.022097\n",
            " month_wom_November_w2     0.018822  0.018822\n",
            "  month_wom_January_w2    -0.018327  0.018327\n",
            "  month_wom_October_w3     0.017734  0.017734\n",
            "  month_wom_January_w5    -0.017437  0.017437\n",
            "  month_wom_January_w3    -0.016737  0.016737\n",
            " month_wom_February_w1    -0.016700  0.016700\n",
            "  month_wom_January_w4    -0.015362  0.015362\n",
            "month_wom_September_w4     0.013558  0.013558\n",
            "\n",
            "======================================================================\n",
            "ðŸŽ¯ ANSWER FOR QUESTION 1:\n",
            "======================================================================\n",
            "Feature: month_wom_October_w4\n",
            "Correlation: 0.024968\n",
            "\n",
            "âœ… ABSOLUTE CORRELATION (3 decimals): 0.025\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STAGE 2: ADD MORE HANDCRAFTED RULES (TODO 2)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 2: Define Handcrafted Prediction Rules\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Original manual predictions from Module 3\n",
        "new_df['pred0_manual_cci'] = (new_df.cci > 200).astype(int)\n",
        "new_df['pred1_manual_prev_g1'] = (new_df.growth_30d > 1).astype(int)\n",
        "new_df['pred2_manual_prev_g1_and_snp'] = ((new_df['growth_30d'] > 1) & (new_df['growth_snp500_30d'] > 1)).astype(int)\n",
        "\n",
        "# TODO 2: Add more handcrafted rules\n",
        "# Rule 3: RSI oversold (RSI < 30) suggests potential upward movement\n",
        "new_df['pred3_manual_rsi_oversold'] = (new_df.rsi < 30).astype(int)\n",
        "\n",
        "# Rule 4: Positive momentum with volume increase\n",
        "new_df['pred4_manual_mom_volume'] = ((new_df.mom > 0) & (new_df.ln_volume > new_df.ln_volume.rolling(30).mean())).astype(int)\n",
        "\n",
        "# Rule 5: October/November positive bias (from correlation analysis)\n",
        "new_df['pred5_manual_oct_nov'] = ((new_df.Month == 'October') | (new_df.Month == 'November')).astype(int)\n",
        "\n",
        "# Rule 6: Strong uptrend (SMA10 > SMA20 and positive growth)\n",
        "new_df['pred6_manual_sma_uptrend'] = ((new_df.SMA10 > new_df.SMA20) & (new_df.growth_30d > 0)).astype(int)\n",
        "\n",
        "# Rule 7: MACD bullish crossover\n",
        "new_df['pred7_manual_macd_cross'] = (new_df.macd > new_df.macdsignal).astype(int)\n",
        "\n",
        "PREDICTIONS = [k for k in new_df.keys() if k.startswith('pred')]\n",
        "print(f\"\\nâœ“ Created {len(PREDICTIONS)} prediction rules:\")\n",
        "for pred in PREDICTIONS:\n",
        "    print(f\"  - {pred}\")\n",
        "\n",
        "# Generate is_correct columns for all predictions\n",
        "for pred in PREDICTIONS:\n",
        "    part1 = pred.split('_')[0]\n",
        "    new_df[f'is_correct_{part1}'] = (new_df[pred] == new_df.is_positive_growth_30d_future).astype(int)\n",
        "\n",
        "IS_CORRECT = [k for k in new_df.keys() if k.startswith('is_correct_')]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYgUHjbV-QLk",
        "outputId": "55d93af7-7703-46e3-dced-38a24f729a9a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 2: Define Handcrafted Prediction Rules\n",
            "======================================================================\n",
            "\n",
            "âœ“ Created 8 prediction rules:\n",
            "  - pred0_manual_cci\n",
            "  - pred1_manual_prev_g1\n",
            "  - pred2_manual_prev_g1_and_snp\n",
            "  - pred3_manual_rsi_oversold\n",
            "  - pred4_manual_mom_volume\n",
            "  - pred5_manual_oct_nov\n",
            "  - pred6_manual_sma_uptrend\n",
            "  - pred7_manual_macd_cross\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STAGE 3: TEMPORAL SPLIT (from Module 3)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 3: Temporal Train/Validation/Test Split\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def temporal_split(df, min_date, max_date, train_prop=0.7, val_prop=0.15, test_prop=0.15):\n",
        "    train_end = min_date + pd.Timedelta(days=(max_date - min_date).days * train_prop)\n",
        "    val_end = train_end + pd.Timedelta(days=(max_date - min_date).days * val_prop)\n",
        "\n",
        "    split_labels = []\n",
        "    for date in df['Date']:\n",
        "        if date <= train_end:\n",
        "            split_labels.append('train')\n",
        "        elif date <= val_end:\n",
        "            split_labels.append('validation')\n",
        "        else:\n",
        "            split_labels.append('test')\n",
        "\n",
        "    df['split'] = split_labels\n",
        "    return df\n",
        "\n",
        "min_date_df = new_df.Date.min()\n",
        "max_date_df = new_df.Date.max()\n",
        "\n",
        "new_df = temporal_split(new_df, min_date=min_date_df, max_date=max_date_df)\n",
        "\n",
        "split_counts = new_df['split'].value_counts()\n",
        "print(f\"\\nâœ“ Split distribution:\")\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    count = split_counts[split]\n",
        "    pct = count / len(new_df) * 100\n",
        "    print(f\"  {split}: {count} ({pct:.1f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN-ioRHd-SZL",
        "outputId": "91d79583-4b05-40db-f93f-1c939621646f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 3: Temporal Train/Validation/Test Split\n",
            "======================================================================\n",
            "\n",
            "âœ“ Split distribution:\n",
            "  train: 129730 (67.6%)\n",
            "  validation: 30657 (16.0%)\n",
            "  test: 31408 (16.4%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STAGE 4: EVALUATE MANUAL PREDICTIONS ON TEST SET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 4: Evaluate Manual Predictions (Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n{'Prediction':<35} {'Precision':<15} {'Count (pred=1)'}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for i, is_correct_col in enumerate(IS_CORRECT):\n",
        "    prediction_col = PREDICTIONS[i]\n",
        "    filter_pred = (new_df.split == 'test') & (new_df[prediction_col] == 1)\n",
        "\n",
        "    if filter_pred.sum() > 0:\n",
        "        precision = new_df[filter_pred][is_correct_col].mean()\n",
        "        count = filter_pred.sum()\n",
        "        print(f\"{prediction_col:<35} {precision:.4f}          {count}\")\n",
        "    else:\n",
        "        print(f\"{prediction_col:<35} N/A (no predictions)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uASFeBFj-aU8",
        "outputId": "53401eed-57ee-46a0-e031-39c1ca98e0ef"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 4: Evaluate Manual Predictions (Test Set)\n",
            "======================================================================\n",
            "\n",
            "Prediction                          Precision       Count (pred=1)\n",
            "-----------------------------------------------------------------\n",
            "pred0_manual_cci                    0.5579          794\n",
            "pred1_manual_prev_g1                0.5418          17991\n",
            "pred2_manual_prev_g1_and_snp        0.5225          13367\n",
            "pred3_manual_rsi_oversold           0.5357          911\n",
            "pred4_manual_mom_volume             0.5517          7401\n",
            "pred5_manual_oct_nov                0.6762          5518\n",
            "pred6_manual_sma_uptrend            0.5409          17488\n",
            "pred7_manual_macd_cross             0.5532          15809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STAGE 5: TRAIN DECISION TREE MODELS (TODO 3)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 5: Train Decision Tree Models\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare data\n",
        "features_list = NUMERICAL + DUMMIES\n",
        "to_predict = 'is_positive_growth_30d_future'\n",
        "\n",
        "train_df = new_df[new_df.split.isin(['train', 'validation'])].copy(deep=True)\n",
        "test_df = new_df[new_df.split.isin(['test'])].copy(deep=True)\n",
        "\n",
        "X_train = train_df[features_list + [to_predict, 'Date', 'Ticker']]\n",
        "X_test = test_df[features_list + [to_predict, 'Date', 'Ticker']]\n",
        "\n",
        "# Clean data\n",
        "pd.options.mode.chained_assignment = None\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)\n",
        "\n",
        "y_train = X_train[to_predict]\n",
        "y_test = X_test[to_predict]\n",
        "\n",
        "del X_train[to_predict]\n",
        "del X_test[to_predict]\n",
        "\n",
        "print(f\"\\nâœ“ X_train: {X_train.shape}\")\n",
        "print(f\"âœ“ X_test: {X_test.shape}\")\n",
        "\n",
        "# Function to train and evaluate decision tree\n",
        "def train_and_evaluate_tree(X_train, y_train, X_test, y_test, max_depth, name):\n",
        "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "    clf.fit(X_train.drop(['Date', 'Ticker'], axis=1), y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test.drop(['Date', 'Ticker'], axis=1))\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{name} (depth={max_depth}):\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "\n",
        "    return clf, y_pred, accuracy, precision\n",
        "\n",
        "# Train models with different depths\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Training Decision Trees with different depths:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "clf_5, pred_5, acc_5, prec_5 = train_and_evaluate_tree(X_train, y_train, X_test, y_test, 5, \"Tree depth 5\")\n",
        "clf_10, pred_10, acc_10, prec_10 = train_and_evaluate_tree(X_train, y_train, X_test, y_test, 10, \"Tree depth 10\")\n",
        "clf_20, pred_20, acc_20, prec_20 = train_and_evaluate_tree(X_train, y_train, X_test, y_test, 20, \"Tree depth 20\")\n",
        "\n",
        "# Add predictions to dataframe\n",
        "X_test['pred_tree_clf5'] = pred_5\n",
        "X_test['pred_tree_clf10'] = pred_10\n",
        "X_test['pred_tree_clf20'] = pred_20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LI8wpWv-fh1",
        "outputId": "b2fe9427-2429-40f3-eedd-8f00aab224b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 5: Train Decision Tree Models\n",
            "======================================================================\n",
            "\n",
            "âœ“ X_train: (160387, 301)\n",
            "âœ“ X_test: (31408, 301)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Training Decision Trees with different depths:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Tree depth 5 (depth=5):\n",
            "  Accuracy:  0.5991\n",
            "  Precision: 0.6278\n",
            "\n",
            "Tree depth 10 (depth=10):\n",
            "  Accuracy:  0.5574\n",
            "  Precision: 0.5880\n",
            "\n",
            "Tree depth 20 (depth=20):\n",
            "  Accuracy:  0.5516\n",
            "  Precision: 0.5961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STAGE 6: TODO 3 - HYPERPARAMETER TUNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 6: Hyperparameter Tuning (Find Best Depth)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Split train into train and validation\n",
        "train_only_df = new_df[new_df.split == 'train'].copy()\n",
        "valid_df = new_df[new_df.split == 'validation'].copy()\n",
        "\n",
        "X_train_only = train_only_df[features_list + [to_predict, 'Date', 'Ticker']]\n",
        "X_valid = valid_df[features_list + [to_predict, 'Date', 'Ticker']]\n",
        "\n",
        "X_train_only.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train_only.fillna(0, inplace=True)\n",
        "X_valid.fillna(0, inplace=True)\n",
        "\n",
        "y_train_only = X_train_only[to_predict]\n",
        "y_valid = X_valid[to_predict]\n",
        "\n",
        "del X_train_only[to_predict]\n",
        "del X_valid[to_predict]\n",
        "\n",
        "# Test depths from 1 to 20\n",
        "depths = range(1, 21)\n",
        "results = []\n",
        "\n",
        "print(\"\\nTesting depths 1-20 on validation set:\")\n",
        "print(f\"\\n{'Depth':<8} {'Accuracy':<12} {'Precision':<12}\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "for depth in depths:\n",
        "    clf = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    clf.fit(X_train_only.drop(['Date', 'Ticker'], axis=1), y_train_only)\n",
        "\n",
        "    y_pred_valid = clf.predict(X_valid.drop(['Date', 'Ticker'], axis=1))\n",
        "\n",
        "    accuracy = accuracy_score(y_valid, y_pred_valid)\n",
        "    precision = precision_score(y_valid, y_pred_valid)\n",
        "\n",
        "    results.append({\n",
        "        'depth': depth,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision\n",
        "    })\n",
        "\n",
        "    print(f\"{depth:<8} {accuracy:<12.4f} {precision:<12.4f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Find best depth by accuracy\n",
        "best_idx_acc = results_df['accuracy'].idxmax()\n",
        "best_depth_acc = results_df.loc[best_idx_acc, 'depth']\n",
        "best_accuracy = results_df.loc[best_idx_acc, 'accuracy']\n",
        "\n",
        "# Find best depth by precision\n",
        "best_idx_prec = results_df['precision'].idxmax()\n",
        "best_depth_prec = results_df.loc[best_idx_prec, 'depth']\n",
        "best_precision = results_df.loc[best_idx_prec, 'precision']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸŽ¯ HYPERPARAMETER TUNING RESULTS:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best depth by Accuracy:  {int(best_depth_acc)} (accuracy: {best_accuracy:.4f})\")\n",
        "print(f\"Best depth by Precision: {int(best_depth_prec)} (precision: {best_precision:.4f})\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Visualize results\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=results_df['depth'], y=results_df['accuracy'],\n",
        "                         mode='lines+markers', name='Accuracy'))\n",
        "fig.add_trace(go.Scatter(x=results_df['depth'], y=results_df['precision'],\n",
        "                         mode='lines+markers', name='Precision'))\n",
        "fig.update_layout(title='Decision Tree Performance vs Depth',\n",
        "                  xaxis_title='Tree Depth',\n",
        "                  yaxis_title='Score',\n",
        "                  hovermode='x')\n",
        "fig.show()\n",
        "\n",
        "# Train best model on full train+validation and evaluate on test\n",
        "print(f\"\\nâœ“ Training final model with best depth ({int(best_depth_acc)}) on full train+validation...\")\n",
        "clf_best, pred_best, acc_best, prec_best = train_and_evaluate_tree(\n",
        "    X_train, y_train, X_test, y_test, int(best_depth_acc), f\"Best Tree\"\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… All stages completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5YnJCHj-p-O",
        "outputId": "914bc16b-f129-4bf0-a3ff-ce726cb61faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 6: Hyperparameter Tuning (Find Best Depth)\n",
            "======================================================================\n",
            "\n",
            "Testing depths 1-20 on validation set:\n",
            "\n",
            "Depth    Accuracy     Precision   \n",
            "-----------------------------------\n",
            "1        0.5622       0.6279      \n",
            "2        0.5622       0.6279      \n",
            "3        0.5623       0.6276      \n",
            "4        0.5090       0.6238      \n",
            "5        0.5211       0.6322      \n",
            "6        0.5412       0.6355      \n",
            "7        0.5053       0.6196      \n",
            "8        0.4956       0.6038      \n",
            "9        0.4954       0.6158      \n",
            "10       0.5108       0.6282      \n",
            "11       0.4965       0.6184      \n",
            "12       0.5143       0.6424      \n",
            "13       0.5390       0.6607      \n",
            "14       0.5140       0.6345      \n",
            "15       0.5127       0.6439      \n",
            "16       0.5038       0.6315      \n",
            "17       0.5067       0.6356      \n"
          ]
        }
      ]
    }
  ]
}