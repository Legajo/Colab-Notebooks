{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeqvJnOu0+l3qIhajcb66E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Legajo/Colab-Notebooks/blob/main/HW3_Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QSsYxi_zWLe",
        "outputId": "14d34c4b-e66b-4621-d73d-6d2722afedc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STAGE 0: SETUP AND DATA LOADING\n",
            "======================================================================\n",
            "\n",
            "✓ Importing libraries...\n",
            "✓ Libraries imported successfully\n",
            "\n",
            "✓ Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✓ Google Drive mounted\n",
            "\n",
            "✓ Installing packages...\n",
            "\n",
            "✓ File found in /content/\n",
            "\n",
            "Loading data from: /content/stocks_df_combined_2025_06_13.parquet.brotli\n",
            "✓ Loaded df_full: (230262, 203)\n",
            "✓ Truncated to df: (191795, 203)\n",
            "\n",
            "✓ Features defined: 184 numerical, 4 categorical\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# HOMEWORK: Time Series Modeling with Decision Trees\n",
        "# Based on: [2025]_Module_3_Colab_Time_Series_Modeling.ipynb\n",
        "# Location: My Drive\\Colab-Notebooks\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# STAGE 0: SETUP AND DATA LOADING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"STAGE 0: SETUP AND DATA LOADING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Import libraries FIRST (before anything else)\n",
        "print(\"\\n✓ Importing libraries...\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import calendar\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"\\n✓ Mounting Google Drive...\")\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✓ Google Drive mounted\")\n",
        "except:\n",
        "    print(\"⚠️  Not in Colab environment or Drive already mounted\")\n",
        "\n",
        "# Install required packages\n",
        "print(\"\\n✓ Installing packages...\")\n",
        "!pip install gdown -q\n",
        "\n",
        "# Check if file exists, if not download it\n",
        "import os\n",
        "\n",
        "# Try Google Drive first (permanent storage)\n",
        "drive_path = \"/content/drive/MyDrive/Colab-Notebooks/stocks_df_combined_2025_06_13.parquet.brotli\"\n",
        "content_path = \"/content/stocks_df_combined_2025_06_13.parquet.brotli\"\n",
        "\n",
        "if os.path.exists(drive_path):\n",
        "    print(f\"\\n✓ File found in Google Drive\")\n",
        "    file_path = drive_path\n",
        "elif os.path.exists(content_path):\n",
        "    print(f\"\\n✓ File found in /content/\")\n",
        "    file_path = content_path\n",
        "else:\n",
        "    print(f\"\\n⚠️  File not found. Downloading to /content/...\")\n",
        "    !gdown https://drive.google.com/file/d/1mb0ae2M5AouSDlqcUnIwaHq7avwGNrmB/view?usp=sharing --fuzzy -O /content/\n",
        "    file_path = content_path\n",
        "\n",
        "    if os.path.exists(content_path):\n",
        "        file_size = os.path.getsize(content_path) / (1024*1024)\n",
        "        print(f\"✓ File downloaded successfully! Size: {file_size:.2f} MB\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"❌ Download failed! Please check your internet connection.\")\n",
        "\n",
        "# Load data\n",
        "print(f\"\\nLoading data from: {file_path}\")\n",
        "df_full = pd.read_parquet(file_path)\n",
        "print(f\"✓ Loaded df_full: {df_full.shape}\")\n",
        "\n",
        "# Truncate to 25 years (2000+)\n",
        "df = df_full[df_full.Date >= '2000-01-01'].copy()\n",
        "print(f\"✓ Truncated to df: {df.shape}\")\n",
        "\n",
        "# Define variable lists (from Module 3)\n",
        "GROWTH = [g for g in df.keys() if (g.find('growth_')==0)&(g.find('future')<0)]\n",
        "OHLCV = ['Open','High','Low','Close','Adj Close_x','Volume']\n",
        "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type']\n",
        "TO_PREDICT = [g for g in df.keys() if (g.find('future')>=0)]\n",
        "TO_DROP = ['Year','Date','index_x', 'index_y', 'index', 'Quarter','Adj Close_y'] + CATEGORICAL + OHLCV\n",
        "\n",
        "# Create custom features\n",
        "df['ln_volume'] = df.Volume.apply(lambda x: np.log(x) if x > 0 else 0)\n",
        "\n",
        "CUSTOM_NUMERICAL = ['SMA10', 'SMA20', 'growing_moving_average', 'high_minus_low_relative','volatility', 'ln_volume']\n",
        "\n",
        "TECHNICAL_INDICATORS = ['adx', 'adxr', 'apo', 'aroon_1','aroon_2', 'aroonosc',\n",
        " 'bop', 'cci', 'cmo','dx', 'macd', 'macdsignal', 'macdhist', 'macd_ext',\n",
        " 'macdsignal_ext', 'macdhist_ext', 'macd_fix', 'macdsignal_fix',\n",
        " 'macdhist_fix', 'mfi', 'minus_di', 'mom', 'plus_di', 'dm', 'ppo',\n",
        " 'roc', 'rocp', 'rocr', 'rocr100', 'rsi', 'slowk', 'slowd', 'fastk',\n",
        " 'fastd', 'fastk_rsi', 'fastd_rsi', 'trix', 'ultosc', 'willr',\n",
        " 'ad', 'adosc', 'obv', 'atr', 'natr', 'ht_dcperiod', 'ht_dcphase',\n",
        " 'ht_phasor_inphase', 'ht_phasor_quadrature', 'ht_sine_sine', 'ht_sine_leadsine',\n",
        " 'ht_trendmod', 'avgprice', 'medprice', 'typprice', 'wclprice']\n",
        "\n",
        "TECHNICAL_PATTERNS = [g for g in df.keys() if g.find('cdl')>=0]\n",
        "\n",
        "MACRO = ['gdppot_us_yoy', 'gdppot_us_qoq', 'cpi_core_yoy', 'cpi_core_mom', 'FEDFUNDS',\n",
        " 'DGS1', 'DGS5', 'DGS10']\n",
        "\n",
        "NUMERICAL = GROWTH + TECHNICAL_INDICATORS + TECHNICAL_PATTERNS + CUSTOM_NUMERICAL + MACRO\n",
        "\n",
        "print(f\"\\n✓ Features defined: {len(NUMERICAL)} numerical, {len(CATEGORICAL)} categorical\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STAGE 1: QUESTION 1 - DUMMIES FOR MONTH AND WEEK-OF-MONTH\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 1: QUESTION 1 - Month and Week-of-Month Dummies\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Step 1: Define week_of_month function (CALENDAR-BASED APPROACH)\n",
        "# Reference: https://stackoverflow.com/questions/3806473/\n",
        "def week_of_month(tgtdate):\n",
        "    \"\"\"\n",
        "    Calculate week of month based on calendar weeks.\n",
        "    Finds the first day where (day - weekday) > 0, then calculates week number.\n",
        "    \"\"\"\n",
        "    if isinstance(tgtdate, pd.Timestamp):\n",
        "        tgtdate = tgtdate.to_pydatetime()\n",
        "\n",
        "    days_this_month = calendar.monthrange(tgtdate.year, tgtdate.month)[1]\n",
        "\n",
        "    # Find the first day where (day - weekday) > 0\n",
        "    for i in range(1, days_this_month + 1):\n",
        "        d = datetime.datetime(tgtdate.year, tgtdate.month, i)\n",
        "        if d.day - d.weekday() > 0:\n",
        "            startdate = d\n",
        "            break\n",
        "    else:\n",
        "        # If no such day found, use first day of month\n",
        "        startdate = datetime.datetime(tgtdate.year, tgtdate.month, 1)\n",
        "\n",
        "    # Calculate week number using modulo 7 approach\n",
        "    return (tgtdate - startdate).days // 7 + 1\n",
        "\n",
        "# Step 2: Create month_wom feature\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.loc[:, 'Month'] = df['Date'].dt.strftime('%B')\n",
        "df.loc[:, 'Weekday'] = df['Date'].dt.day_name().astype(str)\n",
        "df['calendar_wom'] = df['Date'].apply(week_of_month)\n",
        "df['month_wom'] = df['Month'] + '_w' + df['calendar_wom'].astype(str)\n",
        "\n",
        "print(f\"\\n✓ Created month_wom feature (calendar-based)\")\n",
        "print(f\"  Total unique combinations: {df['month_wom'].nunique()}\")\n",
        "print(f\"\\n  Sample values:\")\n",
        "print(df['month_wom'].value_counts().head(10))\n",
        "\n",
        "# Step 3: Update CATEGORICAL list\n",
        "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom']\n",
        "print(f\"\\n✓ Updated CATEGORICAL: {CATEGORICAL}\")\n",
        "\n",
        "# Step 4: Generate dummy variables\n",
        "print(\"\\n✓ Generating dummy variables...\")\n",
        "dummy_variables = pd.get_dummies(df[CATEGORICAL], dtype='int32')\n",
        "DUMMIES = dummy_variables.keys().to_list()\n",
        "\n",
        "print(f\"  Total dummy variables: {len(DUMMIES)}\")\n",
        "\n",
        "# Filter month_wom dummies\n",
        "month_wom_dummies = [col for col in DUMMIES if col.startswith('month_wom_')]\n",
        "print(f\"  month_wom dummies: {len(month_wom_dummies)}\")\n",
        "\n",
        "# Concatenate dummies with original dataframe\n",
        "df_with_dummies = pd.concat([df, dummy_variables], axis=1)\n",
        "\n",
        "# Step 5-8: Calculate correlations and find highest absolute correlation\n",
        "print(\"\\n✓ Calculating correlations...\")\n",
        "correlation_matrix = df_with_dummies[DUMMIES + ['is_positive_growth_30d_future']].corr()\n",
        "correlations = correlation_matrix['is_positive_growth_30d_future']\n",
        "\n",
        "month_wom_correlations = correlations[month_wom_dummies]\n",
        "\n",
        "# Create dataframe with abs_corr column\n",
        "month_wom_corr_df = pd.DataFrame({\n",
        "    'feature': month_wom_correlations.index,\n",
        "    'correlation': month_wom_correlations.values\n",
        "})\n",
        "month_wom_corr_df['abs_corr'] = month_wom_corr_df['correlation'].abs()\n",
        "month_wom_corr_df = month_wom_corr_df.sort_values('abs_corr', ascending=False)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Top 10 month_wom dummies by absolute correlation:\")\n",
        "print(\"=\"*70)\n",
        "print(month_wom_corr_df.head(10).to_string(index=False))\n",
        "\n",
        "max_abs_corr = month_wom_corr_df['abs_corr'].iloc[0]\n",
        "best_feature = month_wom_corr_df['feature'].iloc[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🎯 ANSWER FOR QUESTION 1:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Feature: {best_feature}\")\n",
        "print(f\"Correlation: {month_wom_corr_df['correlation'].iloc[0]:.6f}\")\n",
        "print(f\"\\n✅ ABSOLUTE CORRELATION (3 decimals): {max_abs_corr:.3f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Update new_df for next stages\n",
        "new_df = df_with_dummies.copy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncR56HNqz8JZ",
        "outputId": "3f47fa19-a027-4189-ae52-1a0fa6aaa6d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 1: QUESTION 1 - Month and Week-of-Month Dummies\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2988794995.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['January' 'January' 'January' ... 'June' 'June' 'June']' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
            "  df.loc[:, 'Month'] = df['Date'].dt.strftime('%B')\n",
            "/tmp/ipython-input-2988794995.py:37: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Monday' 'Tuesday' 'Wednesday' ... 'Wednesday' 'Thursday' 'Friday']' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[:, 'Weekday'] = df['Date'].dt.day_name().astype(str)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Created month_wom feature (calendar-based)\n",
            "  Total unique combinations: 72\n",
            "\n",
            "  Sample values:\n",
            "month_wom\n",
            "June_w2        3889\n",
            "May_w2         3874\n",
            "May_w3         3873\n",
            "June_w1        3867\n",
            "February_w1    3863\n",
            "January_w2     3858\n",
            "February_w2    3842\n",
            "May_w1         3836\n",
            "March_w2       3813\n",
            "March_w1       3812\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✓ Updated CATEGORICAL: ['Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom']\n",
            "\n",
            "✓ Generating dummy variables...\n",
            "  Total dummy variables: 127\n",
            "  month_wom dummies: 72\n",
            "\n",
            "✓ Calculating correlations...\n",
            "\n",
            "======================================================================\n",
            "Top 10 month_wom dummies by absolute correlation:\n",
            "======================================================================\n",
            "               feature  correlation  abs_corr\n",
            " month_wom_November_w3     0.024099  0.024099\n",
            "  month_wom_October_w4     0.022408  0.022408\n",
            "  month_wom_October_w3     0.020813  0.020813\n",
            " month_wom_November_w2     0.019720  0.019720\n",
            "  month_wom_January_w2    -0.017660  0.017660\n",
            "  month_wom_January_w4    -0.016240  0.016240\n",
            " month_wom_February_w0    -0.015121  0.015121\n",
            "month_wom_September_w2    -0.014433  0.014433\n",
            "   month_wom_August_w3    -0.014424  0.014424\n",
            "  month_wom_January_w0    -0.014348  0.014348\n",
            "\n",
            "======================================================================\n",
            "🎯 ANSWER FOR QUESTION 1:\n",
            "======================================================================\n",
            "Feature: month_wom_November_w3\n",
            "Correlation: 0.024099\n",
            "\n",
            "✅ ABSOLUTE CORRELATION (3 decimals): 0.024\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STAGE 2: ADD MORE HANDCRAFTED RULES (TODO 2)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 2: Define Handcrafted Prediction Rules\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Original manual predictions from Module 3\n",
        "new_df['pred0_manual_cci'] = (new_df.cci > 200).astype(int)\n",
        "new_df['pred1_manual_prev_g1'] = (new_df.growth_30d > 1).astype(int)\n",
        "new_df['pred2_manual_prev_g1_and_snp'] = ((new_df['growth_30d'] > 1) & (new_df['growth_snp500_30d'] > 1)).astype(int)\n",
        "\n",
        "# TODO 2: Add more handcrafted rules\n",
        "# Rule 3: RSI oversold (RSI < 30) suggests potential upward movement\n",
        "new_df['pred3_manual_rsi_oversold'] = (new_df.rsi < 30).astype(int)\n",
        "\n",
        "# Rule 4: Positive momentum with volume increase\n",
        "new_df['pred4_manual_mom_volume'] = ((new_df.mom > 0) & (new_df.ln_volume > new_df.ln_volume.rolling(30).mean())).astype(int)\n",
        "\n",
        "# Rule 5: October/November positive bias (from correlation analysis)\n",
        "new_df['pred5_manual_oct_nov'] = ((new_df.Month == 'October') | (new_df.Month == 'November')).astype(int)\n",
        "\n",
        "# Rule 6: Strong uptrend (SMA10 > SMA20 and positive growth)\n",
        "new_df['pred6_manual_sma_uptrend'] = ((new_df.SMA10 > new_df.SMA20) & (new_df.growth_30d > 0)).astype(int)\n",
        "\n",
        "# Rule 7: MACD bullish crossover\n",
        "new_df['pred7_manual_macd_cross'] = (new_df.macd > new_df.macdsignal).astype(int)\n",
        "\n",
        "PREDICTIONS = [k for k in new_df.keys() if k.startswith('pred')]\n",
        "print(f\"\\n✓ Created {len(PREDICTIONS)} prediction rules:\")\n",
        "for pred in PREDICTIONS:\n",
        "    print(f\"  - {pred}\")\n",
        "\n",
        "# Generate is_correct columns for all predictions\n",
        "for pred in PREDICTIONS:\n",
        "    part1 = pred.split('_')[0]\n",
        "    new_df[f'is_correct_{part1}'] = (new_df[pred] == new_df.is_positive_growth_30d_future).astype(int)\n",
        "\n",
        "IS_CORRECT = [k for k in new_df.keys() if k.startswith('is_correct_')]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYgUHjbV-QLk",
        "outputId": "f2e0a29c-685f-4fcb-ccd9-94ee2d0a6c54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 2: Define Handcrafted Prediction Rules\n",
            "======================================================================\n",
            "\n",
            "✓ Created 8 prediction rules:\n",
            "  - pred0_manual_cci\n",
            "  - pred1_manual_prev_g1\n",
            "  - pred2_manual_prev_g1_and_snp\n",
            "  - pred3_manual_rsi_oversold\n",
            "  - pred4_manual_mom_volume\n",
            "  - pred5_manual_oct_nov\n",
            "  - pred6_manual_sma_uptrend\n",
            "  - pred7_manual_macd_cross\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STAGE 3: TEMPORAL SPLIT (from Module 3)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 3: Temporal Train/Validation/Test Split\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def temporal_split(df, min_date, max_date, train_prop=0.7, val_prop=0.15, test_prop=0.15):\n",
        "    train_end = min_date + pd.Timedelta(days=(max_date - min_date).days * train_prop)\n",
        "    val_end = train_end + pd.Timedelta(days=(max_date - min_date).days * val_prop)\n",
        "\n",
        "    split_labels = []\n",
        "    for date in df['Date']:\n",
        "        if date <= train_end:\n",
        "            split_labels.append('train')\n",
        "        elif date <= val_end:\n",
        "            split_labels.append('validation')\n",
        "        else:\n",
        "            split_labels.append('test')\n",
        "\n",
        "    df['split'] = split_labels\n",
        "    return df\n",
        "\n",
        "min_date_df = new_df.Date.min()\n",
        "max_date_df = new_df.Date.max()\n",
        "\n",
        "new_df = temporal_split(new_df, min_date=min_date_df, max_date=max_date_df)\n",
        "\n",
        "split_counts = new_df['split'].value_counts()\n",
        "print(f\"\\n✓ Split distribution:\")\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    count = split_counts[split]\n",
        "    pct = count / len(new_df) * 100\n",
        "    print(f\"  {split}: {count} ({pct:.1f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN-ioRHd-SZL",
        "outputId": "745b3fc9-2fd6-4d7b-87b2-ffbccf700e95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 3: Temporal Train/Validation/Test Split\n",
            "======================================================================\n",
            "\n",
            "✓ Split distribution:\n",
            "  train: 129730 (67.6%)\n",
            "  validation: 30657 (16.0%)\n",
            "  test: 31408 (16.4%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STAGE 4: EVALUATE MANUAL PREDICTIONS ON TEST SET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 4: Evaluate Manual Predictions (Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n{'Prediction':<35} {'Precision':<15} {'Count (pred=1)'}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for i, is_correct_col in enumerate(IS_CORRECT):\n",
        "    prediction_col = PREDICTIONS[i]\n",
        "    filter_pred = (new_df.split == 'test') & (new_df[prediction_col] == 1)\n",
        "\n",
        "    if filter_pred.sum() > 0:\n",
        "        precision = new_df[filter_pred][is_correct_col].mean()\n",
        "        count = filter_pred.sum()\n",
        "        print(f\"{prediction_col:<35} {precision:.4f}          {count}\")\n",
        "    else:\n",
        "        print(f\"{prediction_col:<35} N/A (no predictions)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uASFeBFj-aU8",
        "outputId": "35205d65-4bcd-4eda-ffcc-9291cff1448e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 4: Evaluate Manual Predictions (Test Set)\n",
            "======================================================================\n",
            "\n",
            "Prediction                          Precision       Count (pred=1)\n",
            "-----------------------------------------------------------------\n",
            "pred0_manual_cci                    0.5579          794\n",
            "pred1_manual_prev_g1                0.5418          17991\n",
            "pred2_manual_prev_g1_and_snp        0.5225          13367\n",
            "pred3_manual_rsi_oversold           0.5357          911\n",
            "pred4_manual_mom_volume             0.5517          7401\n",
            "pred5_manual_oct_nov                0.6762          5518\n",
            "pred6_manual_sma_uptrend            0.5409          17488\n",
            "pred7_manual_macd_cross             0.5532          15809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STAGE 5: TRAIN DECISION TREE MODELS (TODO 3)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 5: Train Decision Tree Models\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare data\n",
        "features_list = NUMERICAL + DUMMIES\n",
        "to_predict = 'is_positive_growth_30d_future'\n",
        "\n",
        "train_df = new_df[new_df.split.isin(['train', 'validation'])].copy(deep=True)\n",
        "test_df = new_df[new_df.split.isin(['test'])].copy(deep=True)\n",
        "\n",
        "X_train = train_df[features_list + [to_predict, 'Date', 'Ticker']]\n",
        "X_test = test_df[features_list + [to_predict, 'Date', 'Ticker']]\n",
        "\n",
        "# Clean data\n",
        "pd.options.mode.chained_assignment = None\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)\n",
        "\n",
        "y_train = X_train[to_predict]\n",
        "y_test = X_test[to_predict]\n",
        "\n",
        "del X_train[to_predict]\n",
        "del X_test[to_predict]\n",
        "\n",
        "print(f\"\\n✓ X_train: {X_train.shape}\")\n",
        "print(f\"✓ X_test: {X_test.shape}\")\n",
        "\n",
        "# Function to train and evaluate decision tree\n",
        "def train_and_evaluate_tree(X_train, y_train, X_test, y_test, max_depth, name):\n",
        "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "    clf.fit(X_train.drop(['Date', 'Ticker'], axis=1), y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test.drop(['Date', 'Ticker'], axis=1))\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{name} (depth={max_depth}):\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "\n",
        "    return clf, y_pred, accuracy, precision\n",
        "\n",
        "# Train models with different depths\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Training Decision Trees with different depths:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "clf_5, pred_5, acc_5, prec_5 = train_and_evaluate_tree(X_train, y_train, X_test, y_test, 5, \"Tree depth 5\")\n",
        "clf_10, pred_10, acc_10, prec_10 = train_and_evaluate_tree(X_train, y_train, X_test, y_test, 10, \"Tree depth 10\")\n",
        "clf_20, pred_20, acc_20, prec_20 = train_and_evaluate_tree(X_train, y_train, X_test, y_test, 20, \"Tree depth 20\")\n",
        "\n",
        "# Store predictions separately (don't add to X_test to avoid feature mismatch)\n",
        "test_predictions = {\n",
        "    'pred_tree_clf5': pred_5,\n",
        "    'pred_tree_clf10': pred_10,\n",
        "    'pred_tree_clf20': pred_20\n",
        "}\n",
        "\n",
        "print(f\"\\n✓ Predictions stored for later analysis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LI8wpWv-fh1",
        "outputId": "0988b051-d535-4d83-8941-d681bbe5cb65"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 5: Train Decision Tree Models\n",
            "======================================================================\n",
            "\n",
            "✓ X_train: (160387, 313)\n",
            "✓ X_test: (31408, 313)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Training Decision Trees with different depths:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Tree depth 5 (depth=5):\n",
            "  Accuracy:  0.5991\n",
            "  Precision: 0.6278\n",
            "\n",
            "Tree depth 10 (depth=10):\n",
            "  Accuracy:  0.5550\n",
            "  Precision: 0.5871\n",
            "\n",
            "Tree depth 20 (depth=20):\n",
            "  Accuracy:  0.5399\n",
            "  Precision: 0.5828\n",
            "\n",
            "✓ Predictions stored for later analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STAGE 6: TODO 3 - HYPERPARAMETER TUNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STAGE 6: Hyperparameter Tuning (Find Best Depth)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Split train into train and validation\n",
        "train_only_df = new_df[new_df.split == 'train'].copy()\n",
        "valid_df = new_df[new_df.split == 'validation'].copy()\n",
        "\n",
        "X_train_only = train_only_df[features_list + [to_predict, 'Date', 'Ticker']]\n",
        "X_valid = valid_df[features_list + [to_predict, 'Date', 'Ticker']]\n",
        "\n",
        "X_train_only.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train_only.fillna(0, inplace=True)\n",
        "X_valid.fillna(0, inplace=True)\n",
        "\n",
        "y_train_only = X_train_only[to_predict]\n",
        "y_valid = X_valid[to_predict]\n",
        "\n",
        "del X_train_only[to_predict]\n",
        "del X_valid[to_predict]\n",
        "\n",
        "# Test depths from 1 to 20\n",
        "depths = range(1, 21)\n",
        "results = []\n",
        "\n",
        "print(\"\\nTesting depths 1-20 on validation set:\")\n",
        "print(f\"\\n{'Depth':<8} {'Accuracy':<12} {'Precision':<12}\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "for depth in depths:\n",
        "    clf = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    clf.fit(X_train_only.drop(['Date', 'Ticker'], axis=1), y_train_only)\n",
        "\n",
        "    y_pred_valid = clf.predict(X_valid.drop(['Date', 'Ticker'], axis=1))\n",
        "\n",
        "    accuracy = accuracy_score(y_valid, y_pred_valid)\n",
        "    precision = precision_score(y_valid, y_pred_valid)\n",
        "\n",
        "    results.append({\n",
        "        'depth': depth,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision\n",
        "    })\n",
        "\n",
        "    print(f\"{depth:<8} {accuracy:<12.4f} {precision:<12.4f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Find best depth by accuracy\n",
        "best_idx_acc = results_df['accuracy'].idxmax()\n",
        "best_depth_acc = results_df.loc[best_idx_acc, 'depth']\n",
        "best_accuracy = results_df.loc[best_idx_acc, 'accuracy']\n",
        "\n",
        "# Find best depth by precision\n",
        "best_idx_prec = results_df['precision'].idxmax()\n",
        "best_depth_prec = results_df.loc[best_idx_prec, 'depth']\n",
        "best_precision = results_df.loc[best_idx_prec, 'precision']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🎯 HYPERPARAMETER TUNING RESULTS:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best depth by Accuracy:  {int(best_depth_acc)} (accuracy: {best_accuracy:.4f})\")\n",
        "print(f\"Best depth by Precision: {int(best_depth_prec)} (precision: {best_precision:.4f})\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Visualize results\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=results_df['depth'], y=results_df['accuracy'],\n",
        "                         mode='lines+markers', name='Accuracy'))\n",
        "fig.add_trace(go.Scatter(x=results_df['depth'], y=results_df['precision'],\n",
        "                         mode='lines+markers', name='Precision'))\n",
        "fig.update_layout(title='Decision Tree Performance vs Depth',\n",
        "                  xaxis_title='Tree Depth',\n",
        "                  yaxis_title='Score',\n",
        "                  hovermode='x')\n",
        "fig.show()\n",
        "\n",
        "# Train best model on full train+validation and evaluate on test\n",
        "print(f\"\\n✓ Training final model with best depth ({int(best_depth_acc)}) on full train+validation...\")\n",
        "clf_best, pred_best, acc_best, prec_best = train_and_evaluate_tree(\n",
        "    X_train, y_train, X_test, y_test, int(best_depth_acc), f\"Best Tree\"\n",
        ")\n",
        "\n",
        "print(\"\\n✅ All stages completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n5YnJCHj-p-O",
        "outputId": "3ac8a369-5636-4d67-b6f8-bfd80097d8b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 6: Hyperparameter Tuning (Find Best Depth)\n",
            "======================================================================\n",
            "\n",
            "Testing depths 1-20 on validation set:\n",
            "\n",
            "Depth    Accuracy     Precision   \n",
            "-----------------------------------\n",
            "1        0.5622       0.6279      \n",
            "2        0.5622       0.6279      \n",
            "3        0.5623       0.6276      \n",
            "4        0.5090       0.6238      \n",
            "5        0.5248       0.6407      \n",
            "6        0.5453       0.6431      \n",
            "7        0.5052       0.6197      \n",
            "8        0.5155       0.6223      \n",
            "9        0.5092       0.6180      \n",
            "10       0.5037       0.6245      \n",
            "11       0.4942       0.6184      \n",
            "12       0.5118       0.6375      \n",
            "13       0.5364       0.6587      \n",
            "14       0.5341       0.6505      \n",
            "15       0.5049       0.6391      \n",
            "16       0.5030       0.6293      \n",
            "17       0.5025       0.6352      \n",
            "18       0.5317       0.6455      \n",
            "19       0.5088       0.6363      \n",
            "20       0.5033       0.6361      \n",
            "\n",
            "======================================================================\n",
            "🎯 HYPERPARAMETER TUNING RESULTS:\n",
            "======================================================================\n",
            "Best depth by Accuracy:  3 (accuracy: 0.5623)\n",
            "Best depth by Precision: 13 (precision: 0.6587)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"35f369df-8346-463f-afd9-0f0198cd25ad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"35f369df-8346-463f-afd9-0f0198cd25ad\")) {                    Plotly.newPlot(                        \"35f369df-8346-463f-afd9-0f0198cd25ad\",                        [{\"mode\":\"lines+markers\",\"name\":\"Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0.5621880810255406,0.5621880810255406,0.5622533189809832,0.5090191473399224,0.5248393515347229,0.5453240695436605,0.5052027269465375,0.5155103239064488,0.5091822422285286,0.5036696349936393,0.49424275043220145,0.5117917604462277,0.5364190886257625,0.5341357601852758,0.5049417751247676,0.5030172554392145,0.5024953517956747,0.5317219558339041,0.5088234334735949,0.5033434452164269],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Precision\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0.6278983414473142,0.6278983414473142,0.6276236727302659,0.6238348146542381,0.6407372348126288,0.6430549262447767,0.6196849970434876,0.6223385152121492,0.6180401465503896,0.6245336348219332,0.6184202956911925,0.6374859708193041,0.6587068763201126,0.6505412719891746,0.6390713972842751,0.6292585170340681,0.6352271320708008,0.6455017683465959,0.6362713483817031,0.6361496531219029],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Decision Tree Performance vs Depth\"},\"xaxis\":{\"title\":{\"text\":\"Tree Depth\"}},\"yaxis\":{\"title\":{\"text\":\"Score\"}},\"hovermode\":\"x\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('35f369df-8346-463f-afd9-0f0198cd25ad');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Training final model with best depth (3) on full train+validation...\n",
            "\n",
            "Best Tree (depth=3):\n",
            "  Accuracy:  0.5511\n",
            "  Precision: 0.5511\n",
            "\n",
            "✅ All stages completed!\n"
          ]
        }
      ]
    }
  ]
}